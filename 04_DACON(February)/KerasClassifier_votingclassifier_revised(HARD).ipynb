{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensamble model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras-swa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn==0.21.3 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, Dropout, Activation, BatchNormalization, GaussianNoise, Concatenate, LeakyReLU\n",
    "from keras.models import Model, load_model\n",
    "from keras import optimizers, callbacks\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint,Callback, EarlyStopping\n",
    "from keras import backend as K\n",
    "from swa.keras import SWA # swa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. 패키지 임포트\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. 데이터 불러오기\n",
    "train = pd.read_csv('train.csv', index_col=0) # 코랩 사용 시 경로(/content/drive/My Drive/Colab Notebooks/) 추가\n",
    "test = pd.read_csv('test.csv', index_col=0)\n",
    "sample_submission = pd.read_csv('sample_submission.csv', index_col=0)\n",
    "\n",
    "# 2. Train 데이터의 타입을 Sample_submission에 대응하는 가변수 형태로 변환\n",
    "column_number = {}\n",
    "for i, column in enumerate(sample_submission.columns):\n",
    "    column_number[column] = i\n",
    "    \n",
    "def to_number(x, dic):\n",
    "    return dic[x]\n",
    "\n",
    "train['type_num'] = train['type'].apply(lambda x : to_number(x, column_number))\n",
    "\n",
    "# 3.모델에 적용할 데이터 셋 준비 \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, Normalizer\n",
    "\n",
    "train_x = train.drop(columns=['type', 'type_num'], axis=1)\n",
    "del train_x['fiberID']\n",
    "train_y = train['type_num']\n",
    "test_x = test\n",
    "del test_x['fiberID']\n",
    "\n",
    "x = train_x.copy() \n",
    "\n",
    "down_quantiles = x.quantile(0.002) # 전처리 비율 조정\n",
    "up_quantiles = x.quantile(0.998)\n",
    "\n",
    "outliers_low = (x < down_quantiles)\n",
    "outliers_high = (x > up_quantiles)\n",
    "\n",
    "x[outliers_low] = np.nan\n",
    "x.fillna(down_quantiles, inplace=True)\n",
    "\n",
    "x[outliers_high] = np.nan\n",
    "x.fillna(up_quantiles, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.values\n",
    "train_y = train_y.values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, train_y, stratify=train_y, train_size=0.9)\n",
    "\n",
    "# # 3-1 다중 분류 시 One-hot Encoding\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# onehot_encoder = OneHotEncoder()\n",
    "# y_train = y_train.reshape(len(y_train), -1) \n",
    "# y_val = y_val.reshape(len(y_val), -1)\n",
    "# y_train = onehot_encoder.fit_transform(y_train)\n",
    "# y_val = onehot_encoder.fit_transform(y_val)\n",
    "\n",
    "# print(x_train.shape)\n",
    "# print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "import tensorflow as tf\n",
    "\n",
    "class Gelu(Activation):\n",
    "    def __init__(self, activation, **kwargs):\n",
    "        super(Gelu, self).__init__(activation, **kwargs)\n",
    "        self.__name__='gelu'\n",
    "        \n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * np.power(x, 3))))\n",
    "\n",
    "get_custom_objects().update({'gelu': Gelu(gelu)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "# scaler1=RobustScaler()\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "test_x =scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179991, 20)\n",
      "(179991,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop1 = 0.4\n",
    "drop2 = 0.45\n",
    "drop3 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-24 12:27:10.073881\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "start=datetime.datetime.now()\n",
    "print(start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model\n",
    "- EarlyStop, CosineScheduler, CheckPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_1(epochs=1200, drop=0.45):\n",
    "\n",
    "    inps= Input(shape = (20,))\n",
    "    \n",
    "    la = Dense(128)(inps)\n",
    "    la = Dense(256, activation='relu')(la)\n",
    "    la = Dropout(drop)(la)\n",
    "    la = Dense(256, activation='relu')(la)\n",
    "    la = Dropout(drop)(la)\n",
    "    la = Dense(256, activation='relu')(la)\n",
    "    la = Dropout(drop)(la)\n",
    "    la = Dense(256, activation='relu')(la)\n",
    "    la = Dropout(drop)(la)\n",
    "\n",
    "    outs=Dense(19, activation='softmax',name='output')(la)\n",
    "\n",
    "    models = Model(inputs=inps, outputs=outs)\n",
    "    models.summary()\n",
    "    models.compile(loss=\"sparse_categorical_crossentropy\", \\\n",
    "                   optimizer=Adam(lr=1.e-4, beta_1=0.9, beta_2=0.98, epsilon=1e-08, decay=1e-6),metrics=['accuracy'])\n",
    "    \n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_2(epochs=1200, drop=0.45):\n",
    "\n",
    "    inps= Input(shape = (20,))\n",
    "    \n",
    "    la = Dense(128)(inps)\n",
    "    la = Dense(256, activation='elu')(la)\n",
    "    la = Dropout(drop)(la)\n",
    "    la = Dense(256, activation='elu')(la)\n",
    "    la = Dropout(drop)(la)\n",
    "    la = Dense(256, activation='elu')(la)\n",
    "    la = Dropout(drop)(la)\n",
    "    la = Dense(256, activation='elu')(la)\n",
    "    la = Dropout(drop)(la)\n",
    "    outs=Dense(19, activation='softmax',name='output')(la)\n",
    "\n",
    "    models = Model(inputs=inps, outputs=outs)\n",
    "    models.summary()\n",
    "    models.compile(loss=\"sparse_categorical_crossentropy\", \\\n",
    "                   optimizer=Adam(lr=1.e-4, beta_1=0.9, beta_2=0.98, epsilon=1e-08, decay=1e-6),metrics=['accuracy'])\n",
    "    \n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_3(epochs=1200, drop=0.45):\n",
    "\n",
    "    inps= Input(shape = (20,))\n",
    "    \n",
    "    la = Dense(128)(inps)\n",
    "    la = Dense(256, activation='selu')(la)\n",
    "    la = Dropout(drop)(la)\n",
    "    la = Dense(256, activation='selu')(la)\n",
    "    la = Dropout(drop)(la)\n",
    "    la = Dense(256, activation='selu')(la)\n",
    "    la = Dropout(drop)(la)\n",
    "    la = Dense(256, activation='selu')(la)\n",
    "    la = Dropout(drop)(la)\n",
    "    outs=Dense(19, activation='softmax',name='output')(la)\n",
    "\n",
    "    models = Model(inputs=inps, outputs=outs)\n",
    "    models.summary()\n",
    "    models.compile(loss=\"sparse_categorical_crossentropy\", \\\n",
    "                   optimizer=Adam(lr=1.e-4, beta_1=0.9, beta_2=0.98, epsilon=1e-08, decay=1e-6),metrics=['accuracy'])\n",
    "    \n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_4(epochs=1200, drop=0.45):\n",
    "\n",
    "    inps= Input(shape = (20,))\n",
    "    \n",
    "    la = Dense(128)(inps)\n",
    "    la = Dense(256)(la)\n",
    "    la = Activation(gelu)(la)\n",
    "    la = Dropout(drop)(la)\n",
    "    la = Dense(256)(la)\n",
    "    la = Activation(gelu)(la)\n",
    "    la = Dropout(drop)(la)\n",
    "    la = Dense(256)(la)\n",
    "    la = Activation(gelu)(la)\n",
    "    la = Dropout(drop)(la)\n",
    "    la = Dense(256)(la)\n",
    "    la = Activation(gelu)(la)\n",
    "    la = Dropout(drop)(la)\n",
    "    outs=Dense(19, activation='softmax',name='output')(la)\n",
    "\n",
    "    models = Model(inputs=inps, outputs=outs)\n",
    "    models.summary()\n",
    "    models.compile(loss=\"sparse_categorical_crossentropy\", \\\n",
    "                   optimizer=Adam(lr=1.e-4, beta_1=0.9, beta_2=0.98, epsilon=1e-08, decay=1e-6),metrics=['accuracy'])\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_5(epochs=1200, drop=0.45):\n",
    "\n",
    "    inps= Input(shape = (20,))\n",
    "    \n",
    "    la = Dense(128)(inps)\n",
    "    la = LeakyReLU(alpha=0.07)(la)\n",
    "    la = Dropout(drop)(la)\n",
    "    la = Dense(256)(la)\n",
    "    la = LeakyReLU(alpha=0.07)(la)\n",
    "    la = Dropout(drop)(la)\n",
    "    la = Dense(256)(la)\n",
    "    la = LeakyReLU(alpha=0.07)(la)\n",
    "    la = Dropout(drop)(la)\n",
    "    la = Dense(256)(la)\n",
    "    la = LeakyReLU(alpha=0.07)(la)\n",
    "    la = Dropout(drop)(la)\n",
    "    la = Dense(256)(la)\n",
    "    la = Dropout(drop)(la)\n",
    "    outs=Dense(19, activation='softmax',name='output')(la)\n",
    "\n",
    "    models = Model(inputs=inps, outputs=outs)\n",
    "    models.summary()\n",
    "    models.compile(loss=\"sparse_categorical_crossentropy\", \\\n",
    "                   optimizer=Adam(lr=1.e-4, beta_1=0.9, beta_2=0.98, epsilon=1e-08, decay=1e-6),metrics=['accuracy'])\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_params = { 'validation_split': 1./9. }\n",
    "nepoch1 = 1000\n",
    "nepoch2 = 850\n",
    "nepoch3 = 900\n",
    "\n",
    "model_1a = KerasClassifier(build_fn = model_1, epochs = nepoch1, drop=drop1, verbose=2, batch_size=256, **sk_params)\n",
    "\n",
    "model_1b = KerasClassifier(build_fn = model_1, epochs = nepoch2, drop=drop2, verbose=2, batch_size=256, **sk_params)\n",
    "\n",
    "model_1c = KerasClassifier(build_fn = model_1, epochs = nepoch3, drop=drop3, verbose=2, batch_size=256, **sk_params)\n",
    "\n",
    "model_2a = KerasClassifier(build_fn = model_2, epochs = nepoch1, drop=drop1, verbose=2, batch_size=256, **sk_params)\n",
    "\n",
    "model_2b = KerasClassifier(build_fn = model_2, epochs = nepoch2, drop=drop2, verbose=2, batch_size=256, **sk_params)\n",
    "\n",
    "model_2c = KerasClassifier(build_fn = model_2, epochs = nepoch3, drop=drop3, verbose=2, batch_size=256, **sk_params)\n",
    "\n",
    "model_3a = KerasClassifier(build_fn = model_3, epochs = nepoch1, drop=drop1, verbose=2, batch_size=256, **sk_params)\n",
    "\n",
    "model_3b = KerasClassifier(build_fn = model_3, epochs = nepoch2, drop=drop2, verbose=2, batch_size=256, **sk_params)\n",
    "\n",
    "model_3c = KerasClassifier(build_fn = model_3, epochs = nepoch3, drop=drop3, verbose=2, batch_size=256, **sk_params)\n",
    "\n",
    "model_4a = KerasClassifier(build_fn = model_4, epochs = nepoch1, drop=drop1, verbose=2, batch_size=256, **sk_params)\n",
    "\n",
    "model_4b = KerasClassifier(build_fn = model_4, epochs = nepoch2, drop=drop2, verbose=2, batch_size=256, **sk_params)\n",
    "\n",
    "model_4c = KerasClassifier(build_fn = model_4, epochs = nepoch3, drop=drop3, verbose=2, batch_size=256, **sk_params)\n",
    "\n",
    "model_5a = KerasClassifier(build_fn = model_5, epochs = nepoch1, drop=drop1, verbose=2, batch_size=256, **sk_params)\n",
    "\n",
    "model_5b = KerasClassifier(build_fn = model_5, epochs = nepoch2, drop=drop2, verbose=2, batch_size=256, **sk_params)\n",
    "\n",
    "model_5c = KerasClassifier(build_fn = model_5, epochs = nepoch3, drop=drop3, verbose=2, batch_size=256, **sk_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_clf = VotingClassifier(estimators = [ ('model3', model_1a), ('model4', model_1b), ('model5', model_1c), \n",
    "                                             ('model9', model_4a), ('model10', model_4b), ('model11', model_4c)], voting = 'hard')\n",
    "\n",
    "# ensemble_clf = VotingClassifier(estimators = [ ('model1', model_1a), ],  voting = 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ensemble_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ensemble_clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end=datetime.datetime.now()\n",
    "print(\"걸린 시간:\", end-start)\n",
    "\n",
    "pred_test=ensemble_clf.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 파일 생성\n",
    "submission = pd.DataFrame(data=pred_test, columns=sample_submission.columns, index=sample_submission.index)\n",
    "submission.to_csv('submission_data_KerasClassifier_2.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
